{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35898005-a436-4df1-bc95-84fa609d30b6",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664d802-a69c-42b5-ad90-f7e992fd07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Definition --> train the machine like humans that will act or answering questions as humans \n",
    "\n",
    "eg:- youtube recommendations system ,netflix ,instagram etc\n",
    "\n",
    "--> we train the machine to recommend the things that the user come on these types of platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb1a22-32e8-42c6-a23a-6620660d9eb9",
   "metadata": {},
   "source": [
    " # Why Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f851409-b9ee-46b6-855f-b8c191f5dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Auto pilot cars\n",
    "2. Alexa, Siri, Google Assistant, Bixby, Chatbots, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531f369-13ae-4393-9738-3867c5e84952",
   "metadata": {},
   "source": [
    "## Features and Labels of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9dda21-1456-40af-8000-9dfce2dd9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Anything we see and recognize that are feachers in ML\n",
    "2. Feacher ---> ML ---> Label\n",
    "-> I/P                  O/P\n",
    "-> Cat                  This is cat\n",
    "-> Feachers like        after recognition ML\n",
    "   ear,nose,eye,        declares this is cat\n",
    "   etc.                 or dog\n",
    "3. which feachers match and which should be given as output(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85c5bf-7ad3-4b9d-8984-26f2766cd40d",
   "metadata": {},
   "source": [
    "# Data Collection For ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d666e07-50f3-4c02-98d7-bbddfe2133b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pandas\n",
    "UCI ML repository\n",
    "Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf8a31-098e-4967-a1b7-4ece47251a33",
   "metadata": {},
   "source": [
    "# Types of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995a41f-3b1d-441b-adce-64555f5f7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Supervised ML --> machine knows something beforehand\n",
    "   -> Classification --> recognition of things by pt. 2 above\n",
    "   -> Regression --> pridiction of values using previos data\n",
    "       -> Linear Regression Model\n",
    "       -> Multiple Regression Model\n",
    "       -> Logistic Regression Model\n",
    "2. Unsupervised ML --> not known data seen by ML model and classify no feachers                           \n",
    "                       and labels\n",
    "    -> Clusturing --> Discover the inherent groupings of data such as grouping                           \n",
    "                      customers by purchacing behavior\n",
    "    -> Association--> such as people that buy X also tend to buy Y\n",
    "3. Reinforcement ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059276e2-b7c0-4f71-9327-49f0082674fb",
   "metadata": {},
   "source": [
    "### Scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226f289-041f-4435-8761-78f6fe01597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. simple and efficeint tool for data mining and analysis\n",
    "2. accessible to everybody and reuseable in various contexts\n",
    "3. Build on numpy, scipy, and matplotlib\n",
    "4. open source , commertially useable - BSD licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28acea50-bf79-48a3-8616-4aa9f821430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/chandan/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/chandan/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/chandan/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/chandan/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/chandan/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8c76f8-fc71-4762-b03c-3b2619f5d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.5.0\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /home/chandan/.local/lib/python3.10/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf4fb974-e747-4248-a813-00165c93fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20443ad8-79f8-4c84-85e5-a359685fad05",
   "metadata": {},
   "source": [
    "# Training and test data in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b452eeb-1bd5-4ee1-8f93-43852561d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feachers --> ML --> Label\n",
    "1. Take 60 datasets\n",
    "2. split it into 1-40 and 41-60\n",
    "3. Train the data by 1-40 and then test it with 41-60\n",
    "4. if it shows nearby data then it much accurate ML model\n",
    "   else it is not accurate ML model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a44a-4bfe-4f12-88ec-ce7c93f05d59",
   "metadata": {},
   "source": [
    "# Simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf7b41-d3c4-43cd-8403-1a237e34582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some terms--->\n",
    "1. Bestfit line --> minimise the error --> average of input data\n",
    "2. error --> loss in the values\n",
    "3. loss --> +ve,-ve\n",
    "4. Total loss --> sum of square of all losses (errors)\n",
    "simple linear regression model:-\n",
    "1. Dependend variables ----> home price\n",
    "2. Independent Variables --> area in m(square)\n",
    "3. independent variables improves the model due to min (SSE)->sum of square of errors\n",
    "4. we pridict easily home price by see the area of home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5dc9c-e2c1-43f9-b76a-77266b614d5e",
   "metadata": {},
   "source": [
    "# Multiple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea7d5f-82c6-41f9-9486-1daefc80cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. min errors -> accurate ml model -> need of line which shows min errors \n",
    "   -> use y=mx+b -> this will provide line of min errors \n",
    "2. Folmula --> mx+b (where m=slope(tan theeta), x=values, b=space b/w the 0-slope)\n",
    "3. generalised formula --> f(x1) = w0+w1x1\n",
    "                           f(x1,x2) = w0+w1x1+w2x2\n",
    "                           f(x1,x2,x3....xn) = w0+w1x1+w2x2+w3x3......wnxn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f04c5f-7001-4605-b071-4bd7be77370a",
   "metadata": {},
   "source": [
    "## Linear regression code in python --> sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7941d-72cc-4f2b-bf69-288479075dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "it is in the project file\n",
    "some terms\n",
    "   --> MAE (Mean Absolute Error): Average of absolute differences between \n",
    "       predicted and actual values.\n",
    "\n",
    "   --> MSE (Mean Squared Error): Average of squared differences between \n",
    "       predicted and actual values.\n",
    "\n",
    "   --> RMSE (Root Mean Squared Error): Square root of the average of \n",
    "       squared differences between predicted and actual values.\n",
    "\n",
    "   --> RÂ² Score (R-squared): Proportion of variance in the dependent     \n",
    "       variable explained by the independent variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b343f-b073-4722-8f39-d22f3fa2301d",
   "metadata": {},
   "source": [
    "## working of linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4319d5-d646-451f-8a0a-12a4bb6bbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. line of best fit behind the  seen\n",
    "2. y=mx+b \n",
    "3. SSE = smation_of(mx+b-y')^2 should be minimum\n",
    "4. partial derivation del E/del M   \n",
    "5. line will be y=x/2+2                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13f82612-5b97-41aa-a1f8-2f7c37d21564",
   "metadata": {},
   "source": [
    "<img src=\"behind LRM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646e9d4-54da-4f0e-86b2-7306fd103b19",
   "metadata": {},
   "source": [
    "# Loss function and gradiant decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc9e43-7e60-4f62-ab3e-5a99b2d54230",
   "metadata": {},
   "outputs": [],
   "source": [
    "                            loss function \n",
    "                                 /|\\\n",
    "                                / | \\\n",
    "1. SSE some of square of errors   |    MSE mean square error\n",
    "2. samation of(y-y')^2            |\n",
    "3. differentiation easy           |\n",
    "                                  |\n",
    "                       1. MAE mean absolute error\n",
    "                       2. samation of|y-y'|\n",
    "                       3. differentiation tricky\n",
    "Gradiant decent\n",
    "1. Xnew = x - learning_rate * dy/dx (gradient decent)\n",
    "2. y=x^2 , dy/dx=2x\n",
    "3. exact method computationally expensive\n",
    "4. LF give direction of optimal solution\n",
    "5. fast enough to scale on big data\n",
    "6. easy to understand\n",
    "\n",
    "MSE=samation_lim_i=1-n[(y-y'')^2/n] (L2 loss)\n",
    "MAE=samation_lim_i=1-n[|y-y''|/n] (L1 loss)\n",
    "stipenst decend arrows --> how fast coming to which direction by which shortcut\n",
    "these all are for minimising the loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7148838-98e3-432b-a497-1af2f22d7659",
   "metadata": {},
   "source": [
    "<img src=\"loss fnc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029dc12-ab6b-4b79-9302-4a0246945c7b",
   "metadata": {},
   "source": [
    "<img src=\"gd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef811837-f801-43d2-bd1e-e8860e232804",
   "metadata": {},
   "source": [
    "<img src=\"gd1.png\">                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ad8c8-5993-4437-b56d-356c8cd3df99",
   "metadata": {},
   "source": [
    "# Mini Batch and Stochastic gradient decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd487537-61eb-41da-8834-eb1c749c45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. batch function ---> to compute min loss how much data to be consider\n",
    "2. mini batch gradient decent --> split the data into parts \n",
    "   eg:- 1M data->100,100,100,100....till 1M\n",
    "3. stochastic gradient decent --> single unit of input data only\n",
    "   eg:- 1M data->1,1,1,1,1......till 1M \n",
    "4. gradient decent-->full dataset\n",
    "   eg:- 1M data->whole data\n",
    "Note:- middle is mini batch gradient decent\n",
    "5. learning rates by goldilocks -->use that problem's goldilocks give good \n",
    "   results for the problem\n",
    "6. The \"Goldilocks Principle\" for learning rates means finding a rate that's just right.\n",
    "   If it's too low, training is slow; if it's too high, training is unstable.\n",
    "   The perfect rate helps the model learn efficiently and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f153348-d0e7-44c6-9e35-5d99fdc3a3d0",
   "metadata": {},
   "source": [
    "<img src=\"SGDandMBGD.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054da6d7-7498-4462-9a92-6d1fcf9559eb",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7136c-150c-43c4-8e2d-410b4e37a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. eg:-Emails etc.-->spam or not spam\n",
    "2. data-->classifier-->trained classifier ->it will classify(pridict) new data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cae561-986a-4357-bbc0-b6d6b7b6a3ff",
   "metadata": {},
   "source": [
    "<img src=\"classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a8f65-906b-44fe-b181-1a59dd640822",
   "metadata": {},
   "source": [
    "## KNN -> K Nearest Neighbour Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44878214-2917-41ca-9228-651b6c400c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is in the project file\n",
    "# Working and pros,cons of KNN\n",
    "\n",
    "1. KNN-> value given->check by given value->select the classification which is greater\n",
    "   if both have same no.s then has to  increase the value of K\n",
    "\n",
    "2. pros -> 1.burden on testing \n",
    "           2.have to calculate value of K\n",
    "           3.computation is challenging\n",
    "           4.slow due to much data\n",
    "\n",
    "3. cons -> 1. it is simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599a52d-e6ec-4909-876a-de42d2e05a23",
   "metadata": {},
   "source": [
    "<img src=\"KNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34150005-a14d-4188-af03-492e3d68464c",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c48ec0-6e27-490f-abb5-01d59c86384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Overfitting --> low training error , high testing error\n",
    "   there are two methods to improve it\n",
    "   1. resampling\n",
    "   2. holding a validation dataset\n",
    "2. Underfitting --> high training error , high testing error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32f2a8-75d2-44d4-af54-e24dfea28029",
   "metadata": {},
   "source": [
    "<img src =\"over underfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c03a61-ad7a-40e2-a02a-a000e74f380a",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e84ed-b59f-4626-8bd4-191b438c0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Classifier --> predict probability --> by using regression technique\n",
    "   eg:- good or bad , rain or not , pass or fail  \n",
    "2. generalized linear model\n",
    "   g(E(y))=alpha+beta(x1)+gamma(x2)\n",
    "3. wieghts and bias or intercept y=w^tx+b\n",
    "                                   |    |\n",
    "                                   v    v\n",
    "                             weights    bias or intercept\n",
    "4. sigmoid function \n",
    "   y=1/1+e^-x --> sigmoid fn --> (y'=1/1+e^-y) -=> it will be probability\n",
    "5. log of odds = y\n",
    "6. we can not use mean squared error bcs everything was linear but in \n",
    "   sigmoid function there is non linear results --> error fn will be \n",
    "   non linear --> this will result too many global minimas that why \n",
    "   our gradient decent algorithm will not convert --> so may be in search\n",
    "   of local minima we will loose global minima \n",
    "\n",
    "7. So we use log loss fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c5d62-4c54-4453-bfe1-82dcb03fb1ad",
   "metadata": {},
   "source": [
    "<img src=\"logistic1.png\">\n",
    "<img src=\"logistic2.png\">\n",
    "<img src=\"logistic3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dd7b9-b0a9-4424-942c-2c598bb14b5f",
   "metadata": {},
   "source": [
    "<img src=\"LOR1.png\">\n",
    "<img src=\"LOR2.png\">\n",
    "<img src=\"LOR3.png\">\n",
    "<img src=\"LOR4.png\">\n",
    "<img src=\"LOR5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3b431-1d60-4c1a-a1a5-67db01a68270",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance matrics in Logistic regression\n",
    "1. confusion matrix\n",
    "\n",
    "                   actual\n",
    "                   1    0\n",
    "                 -----------    \n",
    "              1  | TP | FP |\n",
    "   predicted     -----------\n",
    "              0  | FN | TF |\n",
    "                 -----------\n",
    "\n",
    "2. accuracy\n",
    "\n",
    "                  TP+TN\n",
    "   Accuracy =  -------------   = (N%) accuracy\n",
    "                TP+FP+FN+TF\n",
    "\n",
    "3. precision\n",
    "\n",
    "                     TP\n",
    "    precision =    -------\n",
    "                    TP+FP\n",
    "\n",
    "        Note:- 1. main aim is to inc. (TP & TN)  and dec. (FP & FN)\n",
    "               2. Focus on reducing \"FP\"\n",
    "               3. Eg:- email spam or not\n",
    "\n",
    "\n",
    "4. recall\n",
    "\n",
    "                     TP\n",
    "        recall =   -------\n",
    "                    TP+FP\n",
    "\n",
    "           Note:- 1. main aim is to inc. (TP & TN)  and dec. (FP & FN)\n",
    "                  2. Focus on reducing (\"FN\")\n",
    "                  3. Eg:- cancer or not      \n",
    "\n",
    "\n",
    "5. f beta score\n",
    "   1. when focus on precion and recall both so we have to use f beta score\n",
    "   2. Focus on reducing both (\"FP\" and \"FN\")\n",
    "   \n",
    "                    (1+beta^2)*(precision*recall)           \n",
    "    f bbeta score = -----------------------------  \n",
    "                     (beta^2)*[precision+recall]\n",
    "\n",
    "     CASES\n",
    "     1. when FP and FN , both are importent\n",
    "                 (beta=1)\n",
    "                 \n",
    "     2. when (\"FP\") is more importent than (\"FN\")\n",
    "                 (beta=0.5)\n",
    "                 \n",
    "     3. when (\"FN\") is more importent than (\"FP\")\n",
    "                 (beta=2)\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b61bd7-22a7-4e22-8841-ca3841eb9d4b",
   "metadata": {},
   "source": [
    "<img src =\"lor1.png\">\n",
    "<img src =\"lor2.png\">\n",
    "<img src =\"lor3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0d843-2433-4b49-97c6-77a0d10e6732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
